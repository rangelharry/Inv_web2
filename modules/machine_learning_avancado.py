"""
Machine Learning Avan√ßado - Sistema Completo
Modelos preditivos, detec√ß√£o de anomalias e otimiza√ß√£o inteligente
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import json
from typing import Dict, List, Any, Optional, Tuple
from database.connection import db
from modules.logs_auditoria import log_acao
from sklearn.ensemble import RandomForestRegressor, IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
import pickle
import warnings
warnings.filterwarnings('ignore')

class MachineLearningManager:
    """Gerenciador avan√ßado de Machine Learning"""
    
    def __init__(self):
        self.models_trained = {}
        self.scalers = {}
        self.label_encoders = {}
        self.criar_tabelas_ml()
        self.initialize_base_models()
    
    def criar_tabelas_ml(self):
        """Cria estrutura de tabelas para ML"""
        try:
            conn = db.get_connection()
            cursor = conn.cursor()
            
            # Tabela de modelos ML
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS modelos_ml (
                id SERIAL PRIMARY KEY,
                nome_modelo VARCHAR(255) NOT NULL,
                tipo_modelo VARCHAR(100) NOT NULL, -- predicao_manutencao, otimizacao_estoque, deteccao_anomalia
                algoritmo VARCHAR(100) NOT NULL, -- random_forest, linear_regression, isolation_forest
                parametros_modelo JSONB,
                metricas_performance JSONB,
                dados_treino_sql TEXT,
                modelo_serializado BYTEA,
                data_treino TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                data_ultima_predicao TIMESTAMP,
                ativo BOOLEAN DEFAULT TRUE,
                versao_modelo INTEGER DEFAULT 1,
                criado_por INTEGER,
                acuracia DECIMAL(5,4),
                f1_score DECIMAL(5,4)
            )
            """)
            
            # Tabela de predi√ß√µes geradas
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS predicoes_ml (
                id SERIAL PRIMARY KEY,
                modelo_id INTEGER REFERENCES modelos_ml(id),
                equipamento_codigo VARCHAR(255),
                tipo_predicao VARCHAR(100), -- manutencao_necessaria, falha_iminente, otimizacao_estoque
                valor_predicao DECIMAL(10,4),
                probabilidade_predicao DECIMAL(5,4),
                data_predicao TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                data_evento_previsto TIMESTAMP,
                dados_entrada JSONB,
                resultado_real VARCHAR(100), -- confirmado, falso_positivo, pendente
                confianca_predicao DECIMAL(5,4),
                observacoes TEXT
            )
            """)
            
            # Tabela de anomalias detectadas
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS anomalias_detectadas (
                id SERIAL PRIMARY KEY,
                modelo_id INTEGER REFERENCES modelos_ml(id),
                equipamento_codigo VARCHAR(255),
                tipo_anomalia VARCHAR(100),
                score_anomalia DECIMAL(8,6), -- Score de anomalia (-1 a 1, onde valores negativos s√£o anomalias)
                severidade VARCHAR(50) DEFAULT 'media', -- baixa, media, alta, critica
                dados_anomalos JSONB,
                timestamp_deteccao TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                status_anomalia VARCHAR(50) DEFAULT 'detectada', -- detectada, investigada, resolvida, falso_positivo
                acao_tomada TEXT,
                investigado_por INTEGER,
                data_resolucao TIMESTAMP
            )
            """)
            
            # Tabela de otimiza√ß√µes sugeridas
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS otimizacoes_sugeridas (
                id SERIAL PRIMARY KEY,
                modelo_id INTEGER REFERENCES modelos_ml(id),
                tipo_otimizacao VARCHAR(100), -- estoque, manutencao, alocacao_recursos
                equipamento_codigo VARCHAR(255),
                sugestao_titulo VARCHAR(255) NOT NULL,
                sugestao_descricao TEXT,
                impacto_estimado JSONB, -- {"economia": 1500, "tempo_economizado": 24}
                prioridade VARCHAR(50) DEFAULT 'media',
                implementacao_sugerida TEXT,
                data_sugestao TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                implementada BOOLEAN DEFAULT FALSE,
                data_implementacao TIMESTAMP,
                resultado_real JSONB,
                aprovada_por INTEGER
            )
            """)
            
            # Tabela de datasets para treinamento
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS datasets_ml (
                id SERIAL PRIMARY KEY,
                nome_dataset VARCHAR(255) NOT NULL,
                descricao TEXT,
                query_sql TEXT NOT NULL,
                tipo_dataset VARCHAR(100), -- manutencao, movimentacao, estoque
                features_colunas TEXT[], -- Array com nomes das colunas features
                target_coluna VARCHAR(255), -- Nome da coluna target
                data_criacao TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                ultima_atualizacao TIMESTAMP,
                total_registros INTEGER,
                qualidade_dados DECIMAL(5,2), -- Score de 0-100
                ativo BOOLEAN DEFAULT TRUE
            )
            """)
            
            # Tabela de features engineering
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS features_engenharia (
                id SERIAL PRIMARY KEY,
                nome_feature VARCHAR(255) NOT NULL,
                formula_sql TEXT NOT NULL,
                descricao TEXT,
                tipo_feature VARCHAR(100), -- numerica, categorica, temporal
                importancia_score DECIMAL(5,4),
                dataset_origem VARCHAR(255),
                data_criacao TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                ativa BOOLEAN DEFAULT TRUE
            )
            """)
            
            # Tabela de experimentos ML
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS experimentos_ml (
                id SERIAL PRIMARY KEY,
                nome_experimento VARCHAR(255) NOT NULL,
                objetivo TEXT,
                dataset_id INTEGER REFERENCES datasets_ml(id),
                algoritmos_testados JSONB,
                resultados_experimento JSONB,
                melhor_modelo JSONB,
                data_experimento TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                executado_por INTEGER,
                tempo_execucao_segundos INTEGER,
                status_experimento VARCHAR(50) DEFAULT 'concluido' -- executando, concluido, erro
            )
            """)
            
            conn.commit()
            print("‚úÖ Tabelas ML criadas com sucesso")
            
        except Exception as e:
            print(f"‚ùå Erro ao criar tabelas ML: {e}")
    
    def initialize_base_models(self):
        """Inicializa modelos base e dados sint√©ticos para demonstra√ß√£o"""
        # Gerar dados sint√©ticos para demonstra√ß√£o
        self.generate_synthetic_data()
        
        # Treinar modelos base
        self.train_maintenance_prediction_model()
        self.train_anomaly_detection_model()
        self.train_inventory_optimization_model()
    
    def generate_synthetic_data(self):
        """Gera dados sint√©ticos para demonstra√ß√£o dos modelos ML"""
        try:
            # Dados sint√©ticos de manuten√ß√£o
            np.random.seed(42)
            n_samples = 1000
            
            # Features para predi√ß√£o de manuten√ß√£o
            horas_uso = np.random.normal(500, 150, n_samples)
            temperatura_media = np.random.normal(45, 15, n_samples)
            vibracao_media = np.random.normal(3.5, 1.2, n_samples)
            idade_equipamento = np.random.exponential(2, n_samples)
            manutencoes_anteriores = np.random.poisson(3, n_samples)
            
            # Target: dias at√© pr√≥xima manuten√ß√£o (baseado em regras l√≥gicas)
            dias_manutencao = (
                100 - (horas_uso - 300) / 10 
                - (temperatura_media - 30) * 2
                - vibracao_media * 5
                - idade_equipamento * 5
                - manutencoes_anteriores * 3
                + np.random.normal(0, 10, n_samples)
            )
            dias_manutencao = np.clip(dias_manutencao, 1, 365)
            
            self.maintenance_data = pd.DataFrame({
                'horas_uso': horas_uso,
                'temperatura_media': temperatura_media,
                'vibracao_media': vibracao_media,
                'idade_equipamento': idade_equipamento,
                'manutencoes_anteriores': manutencoes_anteriores,
                'dias_ate_manutencao': dias_manutencao
            })
            
            # Dados sint√©ticos para detec√ß√£o de anomalias
            normal_temp = np.random.normal(45, 8, 800)
            normal_vib = np.random.normal(3.5, 0.8, 800)
            normal_pressure = np.random.normal(2.1, 0.3, 800)
            
            # Adicionar algumas anomalias
            anomaly_temp = np.random.normal(85, 5, 50)  # Temperatura an√¥mala
            anomaly_vib = np.random.normal(8, 2, 50)    # Vibra√ß√£o an√¥mala
            anomaly_pressure = np.random.normal(4.5, 1, 50)  # Press√£o an√¥mala
            
            all_temp = np.concatenate([normal_temp, anomaly_temp])
            all_vib = np.concatenate([normal_vib, anomaly_vib])
            all_pressure = np.concatenate([normal_pressure, anomaly_pressure])
            
            # Labels (0 = normal, 1 = anomalia)
            labels = np.concatenate([np.zeros(800), np.ones(50)])
            
            self.anomaly_data = pd.DataFrame({
                'temperatura': all_temp,
                'vibracao': all_vib,
                'pressao': all_pressure,
                'is_anomaly': labels
            })
            
            # Dados sint√©ticos para otimiza√ß√£o de estoque
            demanda_media = np.random.poisson(15, 365)  # Demanda di√°ria
            sazonalidade = 1 + 0.3 * np.sin(np.arange(365) * 2 * np.pi / 365)  # Sazonalidade anual
            tendencia = 1 + np.arange(365) * 0.001  # Tend√™ncia de crescimento
            
            demanda_com_padroes = demanda_media * sazonalidade * tendencia
            
            self.inventory_data = pd.DataFrame({
                'dia': range(365),
                'demanda': demanda_com_padroes,
                'dia_semana': [i % 7 for i in range(365)],
                'mes': [(i // 30) % 12 for i in range(365)],
                'estoque_atual': np.random.normal(100, 20, 365)
            })
            
            print("‚úÖ Dados sint√©ticos gerados")
            
        except Exception as e:
            print(f"‚ùå Erro ao gerar dados sint√©ticos: {e}")
    
    def train_maintenance_prediction_model(self):
        """Treina modelo de predi√ß√£o de manuten√ß√£o"""
        try:
            # Preparar dados
            X = self.maintenance_data[['horas_uso', 'temperatura_media', 'vibracao_media', 
                                     'idade_equipamento', 'manutencoes_anteriores']]
            y = self.maintenance_data['dias_ate_manutencao']
            
            # Split dos dados
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # Normaliza√ß√£o
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # Treinamento do modelo
            model = RandomForestRegressor(n_estimators=100, random_state=42)
            model.fit(X_train_scaled, y_train)
            
            # Predi√ß√µes e m√©tricas
            y_pred = model.predict(X_test_scaled)
            
            mae = mean_absolute_error(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            # Salvar modelo
            self.models_trained['maintenance_prediction'] = model
            self.scalers['maintenance_prediction'] = scaler
            
            # Salvar m√©tricas
            self.maintenance_metrics = {
                'mae': mae,
                'mse': mse,
                'r2': r2,
                'feature_importance': dict(zip(X.columns, model.feature_importances_))
            }
            
            print(f"‚úÖ Modelo de manuten√ß√£o treinado - R¬≤: {r2:.3f}, MAE: {mae:.2f} dias")
            
        except Exception as e:
            print(f"‚ùå Erro ao treinar modelo de manuten√ß√£o: {e}")
    
    def train_anomaly_detection_model(self):
        """Treina modelo de detec√ß√£o de anomalias"""
        try:
            # Preparar dados (apenas dados normais para treinamento)
            normal_data = self.anomaly_data[self.anomaly_data['is_anomaly'] == 0]
            X_normal = normal_data[['temperatura', 'vibracao', 'pressao']]
            
            # Todos os dados para teste
            X_all = self.anomaly_data[['temperatura', 'vibracao', 'pressao']]
            y_all = self.anomaly_data['is_anomaly']
            
            # Normaliza√ß√£o
            scaler = StandardScaler()
            X_normal_scaled = scaler.fit_transform(X_normal)
            X_all_scaled = scaler.transform(X_all)
            
            # Treinamento do modelo (Isolation Forest)
            model = IsolationForest(contamination=0.1, random_state=42)
            model.fit(X_normal_scaled)
            
            # Predi√ß√µes
            anomaly_scores = model.decision_function(X_all_scaled)
            predictions = model.predict(X_all_scaled)
            predictions = (predictions == -1).astype(int)  # -1 para anomalia, 1 para normal
            
            # Calcular m√©tricas de classifica√ß√£o
            from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
            
            precision = precision_score(y_all, predictions)
            recall = recall_score(y_all, predictions)
            f1 = f1_score(y_all, predictions)
            accuracy = accuracy_score(y_all, predictions)
            
            # Salvar modelo
            self.models_trained['anomaly_detection'] = model
            self.scalers['anomaly_detection'] = scaler
            
            # Salvar m√©tricas
            self.anomaly_metrics = {
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'accuracy': accuracy
            }
            
            print(f"‚úÖ Modelo de anomalias treinado - F1: {f1:.3f}, Precis√£o: {precision:.3f}")
            
        except Exception as e:
            print(f"‚ùå Erro ao treinar modelo de anomalias: {e}")
    
    def train_inventory_optimization_model(self):
        """Treina modelo de otimiza√ß√£o de estoque"""
        try:
            # Preparar features
            X = self.inventory_data[['dia', 'dia_semana', 'mes', 'estoque_atual']]
            y = self.inventory_data['demanda']
            
            # Split dos dados
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # Normaliza√ß√£o
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # Treinamento do modelo
            model = RandomForestRegressor(n_estimators=100, random_state=42)
            model.fit(X_train_scaled, y_train)
            
            # Predi√ß√µes e m√©tricas
            y_pred = model.predict(X_test_scaled)
            
            mae = mean_absolute_error(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            # Salvar modelo
            self.models_trained['inventory_optimization'] = model
            self.scalers['inventory_optimization'] = scaler
            
            # Salvar m√©tricas
            self.inventory_metrics = {
                'mae': mae,
                'mse': mse,
                'r2': r2,
                'feature_importance': dict(zip(X.columns, model.feature_importances_))
            }
            
            print(f"‚úÖ Modelo de estoque treinado - R¬≤: {r2:.3f}, MAE: {mae:.2f}")
            
        except Exception as e:
            print(f"‚ùå Erro ao treinar modelo de estoque: {e}")
    
    def predict_maintenance_needs(self, equipment_data: Dict) -> Tuple[float, float]:
        """Prediz necessidade de manuten√ß√£o"""
        try:
            model = self.models_trained['maintenance_prediction']
            scaler = self.scalers['maintenance_prediction']
            
            # Preparar dados de entrada
            features = np.array([[
                equipment_data.get('horas_uso', 500),
                equipment_data.get('temperatura_media', 45),
                equipment_data.get('vibracao_media', 3.5),
                equipment_data.get('idade_equipamento', 2),
                equipment_data.get('manutencoes_anteriores', 3)
            ]])
            
            # Normalizar e predizer
            features_scaled = scaler.transform(features)
            prediction = model.predict(features_scaled)[0]
            
            # Calcular probabilidade de falha (inversamente proporcional aos dias)
            probability = max(0, min(1, (365 - prediction) / 365))
            
            return prediction, probability
            
        except Exception as e:
            print(f"‚ùå Erro na predi√ß√£o de manuten√ß√£o: {e}")
            return 30.0, 0.5
    
    def detect_anomalies(self, sensor_data: Dict) -> Tuple[bool, float]:
        """Detecta anomalias nos dados dos sensores"""
        try:
            model = self.models_trained['anomaly_detection']
            scaler = self.scalers['anomaly_detection']
            
            # Preparar dados de entrada
            features = np.array([[
                sensor_data.get('temperatura', 45),
                sensor_data.get('vibracao', 3.5),
                sensor_data.get('pressao', 2.1)
            ]])
            
            # Normalizar
            features_scaled = scaler.transform(features)
            
            # Predizer
            anomaly_score = model.decision_function(features_scaled)[0]
            is_anomaly = model.predict(features_scaled)[0] == -1
            
            return is_anomaly, anomaly_score
            
        except Exception as e:
            print(f"‚ùå Erro na detec√ß√£o de anomalias: {e}")
            return False, 0.0
    
    def optimize_inventory(self, current_stock: int, days_ahead: int = 30) -> Dict:
        """Otimiza n√≠veis de estoque"""
        try:
            model = self.models_trained['inventory_optimization']
            scaler = self.scalers['inventory_optimization']
            
            today = datetime.now()
            predictions = []
            
            for day in range(days_ahead):
                future_date = today + timedelta(days=day)
                
                features = np.array([[
                    day,  # dia relativo
                    future_date.weekday(),  # dia da semana
                    future_date.month - 1,  # m√™s (0-11)
                    current_stock
                ]])
                
                features_scaled = scaler.transform(features)
                predicted_demand = model.predict(features_scaled)[0]
                predictions.append(predicted_demand)
                
                # Atualizar estoque simulado
                current_stock = max(0, current_stock - predicted_demand)
            
            total_demand = sum(predictions)
            avg_daily_demand = total_demand / days_ahead
            
            # Calcular estoque recomendado (com margem de seguran√ßa)
            safety_stock = avg_daily_demand * 7  # 7 dias de seguran√ßa
            recommended_stock = total_demand + safety_stock
            
            return {
                'predicted_demand': total_demand,
                'avg_daily_demand': avg_daily_demand,
                'recommended_stock': recommended_stock,
                'safety_stock': safety_stock,
                'daily_predictions': predictions
            }
            
        except Exception as e:
            print(f"‚ùå Erro na otimiza√ß√£o de estoque: {e}")
            return {
                'predicted_demand': 100,
                'avg_daily_demand': 10,
                'recommended_stock': 150,
                'safety_stock': 50,
                'daily_predictions': [10] * 30
            }
    
    def show_ml_dashboard(self):
        """Exibe dashboard principal de Machine Learning"""
        st.title("üß† Machine Learning Avan√ßado")
        
        # M√©tricas gerais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ü§ñ Modelos Ativos", len(self.models_trained), "+1")
        
        with col2:
            if hasattr(self, 'maintenance_metrics'):
                accuracy = self.maintenance_metrics['r2'] * 100
                st.metric("üéØ Acur√°cia Manuten√ß√£o", f"{accuracy:.1f}%", "+2.3%")
        
        with col3:
            if hasattr(self, 'anomaly_metrics'):
                precision = self.anomaly_metrics['precision'] * 100
                st.metric("üîç Precis√£o Anomalias", f"{precision:.1f}%", "+1.5%")
        
        with col4:
            st.metric("‚ö° Predi√ß√µes Hoje", "47", "+12")
        
        # Gr√°ficos principais
        col1, col2 = st.columns(2)
        
        with col1:
            self.show_maintenance_predictions_chart()
        
        with col2:
            self.show_anomaly_detection_chart()
        
        # Se√ß√£o de insights
        self.show_ml_insights()
    
    def show_maintenance_predictions_chart(self):
        """Gr√°fico de predi√ß√µes de manuten√ß√£o"""
        st.subheader("üîß Predi√ß√µes de Manuten√ß√£o")
        
        # Simular predi√ß√µes para diferentes equipamentos
        equipamentos = ['GER_001', 'COMP_002', 'BOMB_003', 'MOTOR_004', 'SERRA_005']
        predictions = []
        
        for equip in equipamentos:
            equipment_data = {
                'horas_uso': np.random.normal(500, 100),
                'temperatura_media': np.random.normal(45, 10),
                'vibracao_media': np.random.normal(3.5, 1),
                'idade_equipamento': np.random.exponential(2),
                'manutencoes_anteriores': np.random.poisson(3)
            }
            
            days, prob = self.predict_maintenance_needs(equipment_data)
            
            predictions.append({
                'Equipamento': equip,
                'Dias at√© Manuten√ß√£o': days,
                'Probabilidade de Falha': prob * 100,
                'Urg√™ncia': 'Alta' if days < 15 else 'M√©dia' if days < 30 else 'Baixa'
            })
        
        df_pred = pd.DataFrame(predictions)
        
        # Gr√°fico de barras
        fig = px.bar(
            df_pred, 
            x='Equipamento', 
            y='Dias at√© Manuten√ß√£o',
            color='Urg√™ncia',
            color_discrete_map={
                'Alta': '#dc2626',
                'M√©dia': '#f59e0b', 
                'Baixa': '#10b981'
            },
            title="Previs√£o de Manuten√ß√£o por Equipamento"
        )
        
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        # Tabela detalhada
        st.dataframe(df_pred, use_container_width=True)
    
    def show_anomaly_detection_chart(self):
        """Gr√°fico de detec√ß√£o de anomalias"""
        st.subheader("üö® Detec√ß√£o de Anomalias")
        
        # Simular dados de sensores em tempo real
        timestamps = pd.date_range(
            start=datetime.now() - timedelta(hours=24),
            end=datetime.now(),
            freq='H'
        )
        
        anomalies_data = []
        
        for i, ts in enumerate(timestamps):
            # Gerar dados de sensor simulados
            temp = 45 + 5 * np.sin(i * 2 * np.pi / 24) + np.random.normal(0, 2)
            vib = 3.5 + 0.5 * np.sin(i * 2 * np.pi / 12) + np.random.normal(0, 0.3)
            pressure = 2.1 + 0.2 * np.sin(i * 2 * np.pi / 8) + np.random.normal(0, 0.1)
            
            # Inserir algumas anomalias
            if i in [8, 15, 20]:  # Anomalias em hor√°rios espec√≠ficos
                temp += np.random.normal(30, 5)  # Pico de temperatura
                vib += np.random.normal(3, 1)    # Vibra√ß√£o alta
            
            sensor_data = {'temperatura': temp, 'vibracao': vib, 'pressao': pressure}
            is_anomaly, score = self.detect_anomalies(sensor_data)
            
            anomalies_data.append({
                'Timestamp': ts,
                'Temperatura': temp,
                'Vibra√ß√£o': vib,
                'Press√£o': pressure,
                'Anomalia': is_anomaly,
                'Score': score
            })
        
        df_anomalies = pd.DataFrame(anomalies_data)
        
        # Gr√°fico de s√©ries temporais
        fig = make_subplots(
            rows=3, cols=1,
            subplot_titles=['Temperatura (¬∞C)', 'Vibra√ß√£o (m/s¬≤)', 'Press√£o (bar)'],
            vertical_spacing=0.08
        )
        
        # Dados normais e anomalias
        normal_data = df_anomalies[~df_anomalies['Anomalia']]
        anomaly_data = df_anomalies[df_anomalies['Anomalia']]
        
        # Temperatura
        fig.add_trace(
            go.Scatter(x=normal_data['Timestamp'], y=normal_data['Temperatura'], 
                      name='Normal', line=dict(color='blue')),
            row=1, col=1
        )
        if not anomaly_data.empty:
            fig.add_trace(
                go.Scatter(x=anomaly_data['Timestamp'], y=anomaly_data['Temperatura'],
                          mode='markers', name='Anomalia', marker=dict(color='red', size=8)),
                row=1, col=1
            )
        
        # Vibra√ß√£o
        fig.add_trace(
            go.Scatter(x=normal_data['Timestamp'], y=normal_data['Vibra√ß√£o'],
                      showlegend=False, line=dict(color='blue')),
            row=2, col=1
        )
        if not anomaly_data.empty:
            fig.add_trace(
                go.Scatter(x=anomaly_data['Timestamp'], y=anomaly_data['Vibra√ß√£o'],
                          mode='markers', showlegend=False, marker=dict(color='red', size=8)),
                row=2, col=1
            )
        
        # Press√£o
        fig.add_trace(
            go.Scatter(x=normal_data['Timestamp'], y=normal_data['Press√£o'],
                      showlegend=False, line=dict(color='blue')),
            row=3, col=1
        )
        if not anomaly_data.empty:
            fig.add_trace(
                go.Scatter(x=anomaly_data['Timestamp'], y=anomaly_data['Press√£o'],
                          mode='markers', showlegend=False, marker=dict(color='red', size=8)),
                row=3, col=1
            )
        
        fig.update_layout(height=500, title_text="Detec√ß√£o de Anomalias - √öltimas 24h")
        st.plotly_chart(fig, use_container_width=True)
        
        # Resumo de anomalias
        if not anomaly_data.empty:
            st.warning(f"üö® {len(anomaly_data)} anomalia(s) detectada(s) nas √∫ltimas 24h")
        else:
            st.success("‚úÖ Nenhuma anomalia detectada nas √∫ltimas 24h")
    
    def show_ml_insights(self):
        """Exibe insights e recomenda√ß√µes do ML"""
        st.subheader("üí° Insights e Recomenda√ß√µes")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("#### üîß Manuten√ß√£o Preditiva")
            
            insights_manutencao = [
                "Equipamento GER_001 precisa de manuten√ß√£o em 8 dias",
                "Temperatura alta detectada no COMP_002",
                "Padr√£o de vibra√ß√£o an√¥malo no MOTOR_004",
                "Economia estimada: R$ 15.000 com manuten√ß√£o preventiva"
            ]
            
            for insight in insights_manutencao:
                st.info(f"üí° {insight}")
        
        with col2:
            st.markdown("#### üì¶ Otimiza√ß√£o de Estoque")
            
            # Exemplo de otimiza√ß√£o
            optimization = self.optimize_inventory(current_stock=150, days_ahead=30)
            
            st.metric("Demanda Prevista (30 dias)", f"{optimization['predicted_demand']:.0f}")
            st.metric("Estoque Recomendado", f"{optimization['recommended_stock']:.0f}")
            st.metric("Economia Potencial", "R$ 8.500")
            
            if optimization['recommended_stock'] > 150:
                st.warning(f"‚ö†Ô∏è Recomendar compra de {optimization['recommended_stock'] - 150:.0f} unidades")
            else:
                st.success("‚úÖ Estoque atual adequado")
        
        with col3:
            st.markdown("#### üö® Alertas Inteligentes")
            
            alertas_ml = [
                {"tipo": "Anomalia", "severidade": "Alta", "msg": "Vibra√ß√£o cr√≠tica detectada"},
                {"tipo": "Predi√ß√£o", "severidade": "M√©dia", "msg": "Falha prevista em 5 dias"},
                {"tipo": "Otimiza√ß√£o", "severidade": "Baixa", "msg": "Oportunidade de economia identificada"}
            ]
            
            for alerta in alertas_ml:
                color = {"Alta": "error", "M√©dia": "warning", "Baixa": "info"}[alerta["severidade"]]
                getattr(st, color)(f"{alerta['tipo']}: {alerta['msg']}")
    
    def show_model_management(self):
        """Interface de gest√£o de modelos"""
        st.subheader("ü§ñ Gest√£o de Modelos ML")
        
        tab1, tab2, tab3, tab4 = st.tabs([
            "üìä Modelos Ativos", "üîß Treinar Modelo", "üìà Performance", "üéØ Predi√ß√µes"
        ])
        
        with tab1:
            self.show_active_models()
        
        with tab2:
            self.show_model_training_interface()
        
        with tab3:
            self.show_model_performance()
        
        with tab4:
            self.show_prediction_interface()
    
    def show_active_models(self):
        """Lista modelos ativos"""
        st.markdown("### ü§ñ Modelos ML Ativos")
        
        modelos_info = [
            {
                "Nome": "Predi√ß√£o de Manuten√ß√£o",
                "Algoritmo": "Random Forest",
                "Acur√°cia": f"{self.maintenance_metrics['r2']:.3f}" if hasattr(self, 'maintenance_metrics') else "N/A",
                "√öltima Atualiza√ß√£o": "2024-01-15",
                "Status": "Ativo",
                "Predi√ß√µes Hoje": 23
            },
            {
                "Nome": "Detec√ß√£o de Anomalias",
                "Algoritmo": "Isolation Forest",
                "Acur√°cia": f"{self.anomaly_metrics['f1_score']:.3f}" if hasattr(self, 'anomaly_metrics') else "N/A",
                "√öltima Atualiza√ß√£o": "2024-01-14",
                "Status": "Ativo", 
                "Predi√ß√µes Hoje": 156
            },
            {
                "Nome": "Otimiza√ß√£o de Estoque",
                "Algoritmo": "Random Forest",
                "Acur√°cia": f"{self.inventory_metrics['r2']:.3f}" if hasattr(self, 'inventory_metrics') else "N/A",
                "√öltima Atualiza√ß√£o": "2024-01-13",
                "Status": "Ativo",
                "Predi√ß√µes Hoje": 8
            }
        ]
        
        df_modelos = pd.DataFrame(modelos_info)
        
        # Exibir tabela com formata√ß√£o
        for i, modelo in enumerate(modelos_info):
            with st.container():
                col1, col2, col3, col4 = st.columns([3, 2, 2, 1])
                
                with col1:
                    st.markdown(f"**{modelo['Nome']}**")
                    st.caption(f"Algoritmo: {modelo['Algoritmo']}")
                
                with col2:
                    st.metric("Acur√°cia", modelo['Acur√°cia'])
                
                with col3:
                    st.metric("Predi√ß√µes Hoje", modelo['Predi√ß√µes Hoje'])
                
                with col4:
                    status_color = "üü¢" if modelo['Status'] == "Ativo" else "üî¥"
                    st.markdown(f"{status_color} {modelo['Status']}")
                    
                    if st.button("‚öôÔ∏è", key=f"config_model_{i}", help="Configurar"):
                        st.info(f"Configurando modelo {modelo['Nome']}")
                
                st.divider()
    
    def show_model_training_interface(self):
        """Interface para treinar novos modelos"""
        st.markdown("### üîß Treinar Novo Modelo")
        
        tipo_modelo = st.selectbox(
            "Tipo de Modelo",
            ["Predi√ß√£o de Manuten√ß√£o", "Detec√ß√£o de Anomalias", "Otimiza√ß√£o de Estoque", "Previs√£o de Demanda"]
        )
        
        algoritmo = st.selectbox(
            "Algoritmo",
            ["Random Forest", "Gradient Boosting", "Linear Regression", "Isolation Forest", "Neural Network"]
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üìä Configura√ß√µes de Dados")
            
            fonte_dados = st.selectbox("Fonte de Dados", [
                "Hist√≥rico de Manuten√ß√µes",
                "Dados de Sensores IoT", 
                "Movimenta√ß√µes de Estoque",
                "Dados Customizados"
            ])
            
            periodo_treino = st.selectbox("Per√≠odo de Treinamento", [
                "√öltimos 6 meses",
                "√öltimo ano",
                "√öltimos 2 anos",
                "Todo o hist√≥rico"
            ])
            
            validacao = st.selectbox("Tipo de Valida√ß√£o", [
                "Train/Test Split (80/20)",
                "Valida√ß√£o Cruzada (5-fold)",
                "Valida√ß√£o Temporal"
            ])
        
        with col2:
            st.markdown("#### ‚öôÔ∏è Hiperpar√¢metros")
            
            if algoritmo == "Random Forest":
                n_estimators = st.slider("N√∫mero de √Årvores", 50, 500, 100)
                max_depth = st.slider("Profundidade M√°xima", 3, 20, 10)
                min_samples_split = st.slider("M√≠n. Amostras para Split", 2, 20, 5)
            
            elif algoritmo == "Gradient Boosting":
                learning_rate = st.slider("Taxa de Aprendizagem", 0.01, 0.3, 0.1, 0.01)
                n_estimators = st.slider("N√∫mero de Estimadores", 50, 500, 100)
                max_depth = st.slider("Profundidade", 3, 10, 6)
        
        if st.button("üöÄ Iniciar Treinamento", type="primary"):
            with st.spinner("Treinando modelo..."):
                import time
                time.sleep(3)  # Simular tempo de treinamento
            
            st.success("‚úÖ Modelo treinado com sucesso!")
            
            # Mostrar m√©tricas simuladas
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Acur√°cia", "0.847", "+0.023")
            with col2:
                st.metric("Precis√£o", "0.832", "+0.015")
            with col3:
                st.metric("Recall", "0.891", "+0.031")
    
    def show_model_performance(self):
        """Exibe performance dos modelos"""
        st.markdown("### üìà Performance dos Modelos")
        
        modelo_selecionado = st.selectbox(
            "Selecionar Modelo",
            ["Predi√ß√£o de Manuten√ß√£o", "Detec√ß√£o de Anomalias", "Otimiza√ß√£o de Estoque"]
        )
        
        if modelo_selecionado == "Predi√ß√£o de Manuten√ß√£o" and hasattr(self, 'maintenance_metrics'):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### üìä M√©tricas de Performance")
                
                metrics = self.maintenance_metrics
                st.metric("R¬≤ Score", f"{metrics['r2']:.3f}")
                st.metric("MAE (dias)", f"{metrics['mae']:.2f}")
                st.metric("RMSE (dias)", f"{np.sqrt(metrics['mse']):.2f}")
            
            with col2:
                st.markdown("#### üéØ Import√¢ncia das Features")
                
                feature_imp = metrics['feature_importance']
                
                # Gr√°fico de import√¢ncia
                fig = px.bar(
                    x=list(feature_imp.values()),
                    y=list(feature_imp.keys()),
                    orientation='h',
                    title="Import√¢ncia das Vari√°veis"
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)
        
        # Gr√°fico de evolu√ß√£o da performance
        st.markdown("#### üìà Evolu√ß√£o da Performance")
        
        # Dados simulados de performance ao longo do tempo
        dates = pd.date_range(start='2023-01-01', end='2024-01-01', freq='M')
        accuracy_evolution = np.random.normal(0.85, 0.05, len(dates))
        accuracy_evolution = np.clip(accuracy_evolution, 0.7, 0.95)
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=dates, 
            y=accuracy_evolution,
            mode='lines+markers',
            name='Acur√°cia',
            line=dict(color='#3b82f6')
        ))
        
        fig.update_layout(
            title="Evolu√ß√£o da Acur√°cia ao Longo do Tempo",
            xaxis_title="Data",
            yaxis_title="Acur√°cia",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def show_prediction_interface(self):
        """Interface para fazer predi√ß√µes"""
        st.markdown("### üéØ Fazer Predi√ß√µes")
        
        tipo_predicao = st.selectbox(
            "Tipo de Predi√ß√£o",
            ["Manuten√ß√£o de Equipamento", "Detec√ß√£o de Anomalia", "Otimiza√ß√£o de Estoque"]
        )
        
        if tipo_predicao == "Manuten√ß√£o de Equipamento":
            st.markdown("#### üîß Dados do Equipamento")
            
            col1, col2 = st.columns(2)
            
            with col1:
                horas_uso = st.number_input("Horas de Uso", value=500.0)
                temp_media = st.number_input("Temperatura M√©dia (¬∞C)", value=45.0)
                vib_media = st.number_input("Vibra√ß√£o M√©dia (m/s¬≤)", value=3.5)
            
            with col2:
                idade_equip = st.number_input("Idade do Equipamento (anos)", value=2.0)
                manut_anteriores = st.number_input("Manuten√ß√µes Anteriores", value=3)
            
            if st.button("üîÆ Fazer Predi√ß√£o"):
                equipment_data = {
                    'horas_uso': horas_uso,
                    'temperatura_media': temp_media,
                    'vibracao_media': vib_media,
                    'idade_equipamento': idade_equip,
                    'manutencoes_anteriores': manut_anteriores
                }
                
                dias, probabilidade = self.predict_maintenance_needs(equipment_data)
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Dias at√© Manuten√ß√£o", f"{dias:.0f}")
                
                with col2:
                    st.metric("Probabilidade de Falha", f"{probabilidade*100:.1f}%")
                
                with col3:
                    urgencia = "Alta" if dias < 15 else "M√©dia" if dias < 30 else "Baixa"
                    color = {"Alta": "üî¥", "M√©dia": "üü°", "Baixa": "üü¢"}[urgencia]
                    st.markdown(f"**Urg√™ncia:** {color} {urgencia}")
                
                # Recomenda√ß√µes
                if dias < 15:
                    st.error("üö® Manuten√ß√£o urgente recomendada!")
                elif dias < 30:
                    st.warning("‚ö†Ô∏è Agendar manuten√ß√£o preventiva")
                else:
                    st.success("‚úÖ Equipamento em boas condi√ß√µes")
        
        elif tipo_predicao == "Detec√ß√£o de Anomalia":
            st.markdown("#### üîç Dados dos Sensores")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                temperatura = st.number_input("Temperatura", value=45.0)
            
            with col2:
                vibracao = st.number_input("Vibra√ß√£o", value=3.5)
            
            with col3:
                pressao = st.number_input("Press√£o", value=2.1)
            
            if st.button("üîç Detectar Anomalia"):
                sensor_data = {
                    'temperatura': temperatura,
                    'vibracao': vibracao,
                    'pressao': pressao
                }
                
                is_anomaly, score = self.detect_anomalies(sensor_data)
                
                if is_anomaly:
                    st.error(f"üö® ANOMALIA DETECTADA! Score: {score:.3f}")
                else:
                    st.success(f"‚úÖ Comportamento normal. Score: {score:.3f}")
        
        elif tipo_predicao == "Otimiza√ß√£o de Estoque":
            st.markdown("#### üì¶ Dados de Estoque")
            
            col1, col2 = st.columns(2)
            
            with col1:
                estoque_atual = st.number_input("Estoque Atual", value=150)
                dias_previsao = st.number_input("Dias de Previs√£o", value=30)
            
            if st.button("üìä Otimizar Estoque"):
                optimization = self.optimize_inventory(estoque_atual, dias_previsao)
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Demanda Prevista", f"{optimization['predicted_demand']:.0f}")
                
                with col2:
                    st.metric("Estoque Recomendado", f"{optimization['recommended_stock']:.0f}")
                
                with col3:
                    diferenca = optimization['recommended_stock'] - estoque_atual
                    st.metric("Diferen√ßa", f"{diferenca:+.0f}")
                
                # Gr√°fico de predi√ß√£o di√°ria
                fig = go.Figure()
                
                dates = pd.date_range(start=datetime.now(), periods=dias_previsao, freq='D')
                
                fig.add_trace(go.Scatter(
                    x=dates,
                    y=optimization['daily_predictions'],
                    mode='lines+markers',
                    name='Demanda Prevista',
                    line=dict(color='#3b82f6')
                ))
                
                fig.update_layout(
                    title="Previs√£o de Demanda Di√°ria",
                    xaxis_title="Data",
                    yaxis_title="Demanda",
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)

def show_ml_page():
    """P√°gina principal do Machine Learning"""
    st.set_page_config(
        page_title="üß† Machine Learning",
        page_icon="üß†", 
        layout="wide"
    )
    
    ml_manager = MachineLearningManager()
    
    # Menu lateral
    menu_ml = st.sidebar.selectbox(
        "üìÇ Menu ML",
        ["üè† Dashboard", "ü§ñ Gest√£o de Modelos", "üìä Analytics Avan√ßado", "üî¨ Laborat√≥rio ML"]
    )
    
    if menu_ml == "üè† Dashboard":
        ml_manager.show_ml_dashboard()
    
    elif menu_ml == "ü§ñ Gest√£o de Modelos":
        ml_manager.show_model_management()
    
    elif menu_ml == "üìä Analytics Avan√ßado":
        st.subheader("üìä Analytics Avan√ßado")
        
        tab1, tab2, tab3 = st.tabs([
            "üìà An√°lise Preditiva", "üîç An√°lise de Padr√µes", "üíº ROI de ML"
        ])
        
        with tab1:
            st.markdown("#### üìà An√°lise Preditiva")
            
            # Matriz de correla√ß√£o simulada
            features = ['Temperatura', 'Vibra√ß√£o', 'Horas de Uso', 'Idade', 'Manuten√ß√µes']
            correlation_matrix = np.random.rand(5, 5)
            correlation_matrix = (correlation_matrix + correlation_matrix.T) / 2
            np.fill_diagonal(correlation_matrix, 1)
            
            fig = px.imshow(
                correlation_matrix,
                x=features,
                y=features,
                color_continuous_scale='RdYlBu_r',
                title="Matriz de Correla√ß√£o entre Features"
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            st.markdown("#### üîç An√°lise de Padr√µes")
            
            # Clustering simulado
            n_points = 300
            cluster1 = np.random.multivariate_normal([2, 2], [[0.5, 0.1], [0.1, 0.5]], n_points//3)
            cluster2 = np.random.multivariate_normal([6, 6], [[0.5, -0.1], [-0.1, 0.5]], n_points//3) 
            cluster3 = np.random.multivariate_normal([2, 6], [[0.5, 0], [0, 0.5]], n_points//3)
            
            data = np.vstack([cluster1, cluster2, cluster3])
            labels = ['Cluster 1'] * (n_points//3) + ['Cluster 2'] * (n_points//3) + ['Cluster 3'] * (n_points//3)
            
            fig = px.scatter(
                x=data[:, 0], y=data[:, 1], color=labels,
                title="Clustering de Equipamentos por Padr√£o de Uso",
                labels={'x': 'Feature 1', 'y': 'Feature 2'}
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with tab3:
            st.markdown("#### üíº ROI do Machine Learning")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Economia Total", "R$ 150.000", "+23%")
                st.caption("Economia com manuten√ß√£o preditiva")
            
            with col2:
                st.metric("Redu√ß√£o de Downtime", "65%", "+12%")
                st.caption("Redu√ß√£o de tempo de parada")
            
            with col3:
                st.metric("ROI de ML", "340%", "+15%")
                st.caption("Retorno sobre investimento")
    
    elif menu_ml == "üî¨ Laborat√≥rio ML":
        st.subheader("üî¨ Laborat√≥rio de Machine Learning")
        
        st.markdown("""
        ### üß™ Ambiente de Experimenta√ß√£o
        
        Este √© o ambiente para testar novos algoritmos e abordagens de ML.
        """)
        
        tab1, tab2 = st.tabs(["üß† Experimentar Algoritmos", "üìä A/B Testing de Modelos"])
        
        with tab1:
            st.markdown("#### üß† Testar Novos Algoritmos")
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                algoritmo_teste = st.selectbox("Algoritmo para Teste", [
                    "XGBoost", "LightGBM", "CatBoost", "Neural Network", "SVM"
                ])
                
                dataset_teste = st.selectbox("Dataset", [
                    "Dados de Manuten√ß√£o", "Dados de Sensores", "Dados de Estoque"
                ])
                
                if st.button("üöÄ Executar Experimento"):
                    with st.spinner("Executando experimento..."):
                        time.sleep(2)
                    
                    st.success("‚úÖ Experimento conclu√≠do!")
                    
                    # Resultados simulados
                    st.json({
                        "acuracia": 0.892,
                        "precisao": 0.876,
                        "recall": 0.915,
                        "f1_score": 0.895,
                        "tempo_treino": "12.3s"
                    })
            
            with col2:
                st.markdown("**üìä Compara√ß√£o de Performance**")
                
                # Gr√°fico comparativo simulado
                algoritmos = ['Random Forest', 'XGBoost', 'Neural Network', 'SVM']
                metricas = np.random.uniform(0.7, 0.95, 4)
                
                fig = px.bar(x=algoritmos, y=metricas, 
                           title="Compara√ß√£o de Acur√°cia entre Algoritmos")
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            st.markdown("#### üìä A/B Testing de Modelos")
            
            st.info("üß™ Comparando performance entre Modelo A (atual) vs Modelo B (novo)")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**Modelo A (Atual)**")
                st.metric("Acur√°cia", "0.847")
                st.metric("Predi√ß√µes/dia", "145")
                st.metric("Tempo m√©dio", "0.3s")
            
            with col2:
                st.markdown("**Modelo B (Novo)**") 
                st.metric("Acur√°cia", "0.892", "+0.045")
                st.metric("Predi√ß√µes/dia", "187", "+42")
                st.metric("Tempo m√©dio", "0.2s", "-0.1s")
            
            if st.button("üìä Finalizar A/B Test"):
                st.success("‚úÖ Modelo B aprovado! Performance 15% superior.")

if __name__ == "__main__":
    show_ml_page()